linear_predictor <- function(draws, i = NULL) {
  # compute the linear predictor (eta) for brms models
  # Args:
  #   draws: a list generated by extract_draws containing
  #     all required data and posterior samples
  #   i: An optional vector indicating the observation(s) 
  #     for which to compute eta. If NULL, eta is computed 
  #     for all all observations at once.
  # Returns:
  #   Usually an S x N matrix where S is the number of samples
  #   and N is the number of observations or length of i if specified. 
  if (length(i) == 1L && is_categorical(draws$f) && 
      isTRUE(draws$old_cat == 2L)) {
    # for some time categorical models were using mv syntax
    nobs <- draws$data$N_trait * (draws$data$ncat - 1)
    i <- seq(i, nobs, draws$data$N_trait)
  }
  N <- ifelse(!is.null(i), length(i), draws$data$N) 
  eta <- matrix(0, nrow = draws$nsamples, ncol = N) +
    predictor_fe(draws, i) +
    predictor_re(draws, i) +
    predictor_mo(draws, i) +
    predictor_me(draws, i) +
    predictor_sm(draws, i) +
    predictor_gp(draws, i) +
    predictor_offset(draws, i, N)
  # some autocorrelation structures depend on eta
  eta <- predictor_autocor(eta, draws, i)
  # intentionally last
  eta <- predictor_cs(eta, draws, i)
  unname(eta)
}

linear_predictor_mv <- function(draws, i = NULL) {
  # compute the linear predictor Eta for multivariate models
  # Returns:
  #   An array of dimension Nsamples (or length(i)) x Nobs x Nresp
  resp <- names(draws[["mv"]])
  tmp <- named_list(resp)
  for (r in resp) {
    tmp[[r]] <- linear_predictor(draws[["mv"]][[r]], i = i)
  }
  aperm(do.call(abind::abind, c(tmp, along = 0)), perm = c(2, 3, 1))
}

nonlinear_predictor <- function(draws, i = NULL) {
  # compute the non-linear predictor (eta) for brms models
  # Args:
  #   draws: a list generated by extract_draws containing
  #          all required data and posterior samples
  #   i: An optional vector indicating the observation(s) 
  #      for which to compute eta. If NULL, eta is computed 
  #      for all all observations at once.
  # Returns:
  #   Usually an S x N matrix where S is the number of samples
  #   and N is the number of observations or length of i if specified. 
  nlmodel_list <- list()
  nlpars <- names(draws$nlpars)
  for (nlp in nlpars) {
    nlmodel_list[[nlp]] <- linear_predictor(draws$nlpars[[nlp]], i = i)
  }
  for (cov in names(draws$C)) {
    nlmodel_list[[cov]] <- p(draws$C[[cov]], i, row = FALSE)  
  }
  # evaluate non-linear predictor
  out <- try(with(nlmodel_list, eval(draws$nlform)), silent = TRUE)
  if (is(out, "try-error")) {
    if (grepl("could not find function", out)) {
      out <- rename(out, "Error in eval(expr, envir, enclos) : ", "")
      stop2(out, " Most likely this is because you used a Stan ",
            "function in the non-linear model formula that ",
            "is not defined in R. Currently, you have to write ",
            "this function yourself making sure that it is ",
            "vectorized. I apologize for the inconvenience.")
    } else {
      out <- rename(out, "^Error :", "", fixed = FALSE)
      stop2(out)
    }
  }
  unname(out)
}

predictor_fe <- function(draws, i) {
  # compute eta for fixed effects
  fe <- draws[["fe"]]
  if (!length(fe)) {
    return(0) 
  }
  eta <- try(.predictor_fe(X = p(fe[["X"]], i), b = fe[["b"]]))
  if (is(eta, "try-error")) {
    stop2(
      "Something went wrong. Did you transform numeric variables ", 
      "to factors or vice versa within the model formula? ",
      "If yes, please convert your variables beforehand. ",
      "If no, this might be a bug. Please tell me about it."
    )
  }
  eta
}

.predictor_fe <- function(X, b) {
  # Args:
  #   X: fixed effects design matrix
  #   b: fixed effects samples
  stopifnot(is.matrix(X))
  stopifnot(is.matrix(b))
  tcrossprod(b, X)
}

predictor_re <- function(draws, i) {
  # compute eta for group-level effects
  eta <- 0
  re <- draws[["re"]]
  group <- names(re[["r"]])
  for (g in group) {
    eta <- eta + 
      .predictor_re(
        Z = p(re[["Z"]][[g]], i),
        r = re[["r"]][[g]]
      )
  }
  eta
}

.predictor_re <- function(Z, r) {
  # Args:
  #   Z: sparse random effects design matrix
  #   r: random effects samples
  # Returns: 
  #   linear predictor for random effects
  Matrix::as.matrix(Matrix::tcrossprod(r, Z))
}

predictor_mo <- function(draws, i) {
  # compute eta for monotonic effects
  eta <- 0
  mo <- draws[["mo"]]
  if (!length(mo)) {
    return(eta) 
  }
  eval_list <- list()
  for (j in seq_along(mo[["simo"]])) {
    eval_list[[paste0("Xmo_", j)]] <- p(mo[["Xmo"]][[j]], i)
    eval_list[[paste0("simo_", j)]] <- mo[["simo"]][[j]]
  }
  for (j in seq_along(mo[["Cmo"]])) {
    eval_list[[paste0("Cmo_", j)]] <- 
      p(mo[["Cmo"]][[j]], i, row = FALSE)
  }
  re <- draws[["re"]]
  monef <- names(mo[["bmo"]])
  for (j in seq_along(monef)) {
    # prepare monotonic group-level effects
    rmo <- named_list(names(re[["rmo"]][[monef[j]]]))
    for (g in names(rmo)) {
      rmo[[g]] <- .predictor_re(
        Z = p(re[["Zmo"]][[g]], i), 
        r = re[["rmo"]][[monef[j]]][[g]]
      )
    }
    eta <- eta + 
      .predictor_mo(
        eval_list, call = mo[["calls"]][[j]],
        b = mo[["bmo"]][[j]], 
        r = Reduce("+", rmo)
      )
  }
  eta
}

.predictor_mo <- function(eval_list, call, b, r = NULL) {
  # compute eta for monotonic effects
  # Args:
  #   call: expression for evaluation of monotonic effects
  #   eval_list: list containing variables for 'call'
  #   b: monotonic effects samples
  #   r: matrix with monotonic group-level samples
  b <- as.vector(b)
  if (is.null(r)) r <- 0 
  (b + r) * eval(call, eval_list)
}

.mo <- function(simplex, X) {
  # R implementation of the user defined Stan function 'mo'
  # Args:
  #   simplex: posterior samples of a simplex parameter vector
  #   X: variable modeled as monotonic
  stopifnot(is.matrix(simplex), is.atomic(X))
  simplex <- cbind(0, simplex)
  for (i in 2:ncol(simplex)) {
    # compute the cumulative representation of the simplex 
    simplex[, i] <- simplex[, i] + simplex[, i - 1]
  }
  simplex[, X + 1]
}

predictor_me <- function(draws, i) {
  # compute eta for noise-free effects
  eta <- 0
  me <- draws[["me"]]
  if (!length(me)) {
    return(eta) 
  }
  eval_list <- list()
  for (j in seq_along(me[["Xme"]])) {
    eval_list[[paste0("Xme_", j)]] <- 
      p(me[["Xme"]][[j]], i, row = FALSE)
  }
  for (j in seq_along(me[["Cme"]])) {
    eval_list[[paste0("Cme_", j)]] <- 
      p(me[["Cme"]][[j]], i, row = FALSE)
  }
  re <- draws[["re"]]
  meef <- names(me[["bme"]])
  for (j in seq_along(meef)) {
    # prepare noise-free group-level effects
    rme_temp <- re[["rme"]][[meef[j]]]
    rme <- named_list(names(rme_temp))
    for (g in names(rme)) {
      rme[[g]] <- .predictor_re(
        Z = p(re[["Zme"]][[g]], i), r = rme_temp[[g]]
      )
    }
    eta <- eta + 
      .predictor_me(
        eval_list, call = me[["calls"]][[j]],
        b = me[["bme"]][[j]],
        r = Reduce("+", rme)
      )
  }
  eta
}

.predictor_me <- function(eval_list, call, b, r = NULL) {
  # Args:
  #   Xme: a matrix of samples of the noise-free variable
  #   b: samples of the noise-free coefficient
  #   r: matrix with meef group-level samples
  b <- as.vector(b)
  if (is.null(r)) r <- 0 
  (b + r) * eval(call, eval_list)
}

predictor_sm <- function(draws, i) {
  # compute eta for smooth terms
  eta <- 0
  smooths <- names(draws[["sm"]])
  for (k in seq_along(smooths)) {
    sm <- draws[["sm"]][[k]]
    nb <- seq_len(length(sm[["s"]]))
    for (j in nb) {
      Zs <- p(sm[["Zs"]][[j]], i)
      s <- sm[["s"]][[j]]
      eta <- eta + .predictor_fe(X = Zs, b = s)
    }
  }
  eta
}

predictor_gp <- function(draws, i) {
  # compute eta for gaussian processes
  eta <- 0
  for (k in seq_along(draws[["gp"]])) {
    if (!is.null(i)) {
      stop2("Pointwise evaluation is currently not ", 
            "supported for Gaussian processes.")
    }
    gp <- draws[["gp"]][[k]]
    gp[["bynum"]] <- p(gp[["bynum"]], i)
    if (!is.null(gp[["x_new"]])) {
      gp[["x_new"]] <- p(gp[["x_new"]], i)
      gp[["Jgp_new"]] <- select_indices(gp[["Jgp_new"]], i)
      eta <- eta + do.call(.predictor_gp, gp)  
    } else {
      gp[["x"]] <- p(gp[["x"]], i)
      gp[["Jgp"]] <- select_indices(gp[["Jgp"]], i)
      gp[["zgp"]] <- p(gp[["zgp"]], i, row = FALSE)
      eta <- eta + do.call(.predictor_gp, gp)  
    }
  }
  eta
}

.predictor_gp <- function(x, sdgp, lscale, zgp = NULL, x_new = NULL,
                          yL = NULL, Jgp = NULL, Jgp_new = NULL,
                          bynum = NULL, nug = 1e-11) {
  # compute predictions for gaussian processes
  # Does not work with pointwise evaluation!
  # Args:
  #   x: old predictor values
  #   sdgp: sample of parameter sdgp
  #   lscale: sample of parameter lscale
  #   zgp: only for old data; samples of parameter vector zgp
  #   x_new: only for new data: new predictor values
  #   yL: only for new data: linear predictor of the old data
  # Returns:
  #   A S x N matrix to be added to the linear predictor
  try_expr <- function(expr) {
    out <- try(expr, silent = TRUE)
    if (is(out, "try-error")) {
      stop2("The Gaussian process covariance matrix is not positive ", 
            "definite.\nThis occurs for numerical reasons. Setting ",
            "'nug' above ", nug, " may help.")
    }
    out
  }
  .predictor_gp_old <- function(x, sdgp, lscale, zgp) {
    Sigma <- cov_exp_quad(x, sdgp = sdgp, lscale = lscale)
    lx <- nrow(x)
    Sigma <- Sigma + diag(rep(nug, lx), lx, lx)
    L_Sigma <- try_expr(t(chol(Sigma)))
    as.numeric(L_Sigma %*% zgp)
  }
  .predictor_gp_new <- function(x_new, yL, x, sdgp, lscale) {
    Sigma <- cov_exp_quad(x, sdgp = sdgp, lscale = lscale)
    lx <- nrow(x)
    lx_new <- nrow(x_new)
    Sigma <- Sigma + diag(rep(nug, lx), lx, lx)
    L_Sigma <- try_expr(t(chol(Sigma)))
    L_Sigma_inverse <- solve(L_Sigma)
    K_div_yL <- L_Sigma_inverse %*% yL
    K_div_yL <- t(t(K_div_yL) %*% L_Sigma_inverse)
    k_x_x_new <- cov_exp_quad(x, x_new, sdgp = sdgp, lscale = lscale)
    mu_yL_new <- as.numeric(t(k_x_x_new) %*% K_div_yL)
    v_new <- L_Sigma_inverse %*% k_x_x_new
    cov_yL_new <- cov_exp_quad(x_new, sdgp = sdgp, lscale = lscale) -
      t(v_new) %*% v_new + diag(rep(nug, lx_new), lx_new, lx_new)
    yL_new <- try_expr(
      rmulti_normal(1, mu = mu_yL_new, Sigma = cov_yL_new)
    )
    return(yL_new)
  }
  nsamples <- nrow(sdgp)
  out <- as.list(rep(NA, nsamples))
  if (!is.null(x_new)) {
    # compute the gaussian process for new data
    stopifnot(!is.null(yL))
    stopifnot(length(Jgp_new) == length(Jgp))
    if (length(Jgp)) {
      # 'by' is a factor variable
      for (i in seq_along(out)) {
        for (j in seq_along(Jgp)) {
          if (length(Jgp_new[[j]])) {
            out[[i]][Jgp_new[[j]]] <- .predictor_gp_new(
              x_new = x_new[Jgp_new[[j]], , drop = FALSE],
              yL = yL[i, Jgp[[j]]], x = x[Jgp[[j]], , drop = FALSE],
              sdgp = sdgp[i, j], lscale = lscale[i, j]
            )
          }
        }
      }
    } else {
      sdgp <- as.numeric(sdgp)
      lscale <- as.numeric(lscale)
      for (i in seq_along(out)) {
        out[[i]] <- .predictor_gp_new(
          x_new = x_new, yL = yL[i, ], x = x, 
          sdgp = sdgp[i], lscale = lscale[i]
        ) 
      }
    }
  } else {
    # compute the gaussian process for the old data
    stopifnot(!is.null(zgp))
    if (length(Jgp)) {
      # 'by' is a factor variable
      for (i in seq_along(out)) {
        for (j in seq_along(Jgp)) {
          if (length(Jgp[[j]])) {
            out[[i]][Jgp[[j]]] <- .predictor_gp_old(
              x = x[Jgp[[j]], , drop = FALSE], sdgp = sdgp[i, j],
              lscale = lscale[i, j], zgp = zgp[i, Jgp[[j]]]
            ) 
          }
        }
      }
    } else {
      sdgp <- as.numeric(sdgp)
      lscale <- as.numeric(lscale)
      for (i in seq_along(out)) {
        out[[i]] <- .predictor_gp_old(
          x = x, sdgp = sdgp[i], lscale = lscale[i], zgp = zgp[i, ]
        )
      }
    }
  }
  out <- do.call(rbind, out) 
  if (!is.null(bynum)) {
    out <- out * as_draws_matrix(bynum, dim = dim(out))
  }
  out
}

predictor_cs <- function(eta, draws, i) {
  # compute eta for category specific effects
  # returns 3-dimensional eta if cs terms are present
  cs <- draws[["cs"]]
  re <- draws[["re"]]
  ncat <- draws$data[["ncat"]]
  if (is_ordinal(draws$f)) {
    if (!is.null(cs) || !is.null(re[["rcs"]])) {
      if (!is.null(re[["rcs"]])) {
        rcs <- named_list(seq_len(ncat - 1))
        for (k in names(rcs)) {
          rcs[[k]] <- named_list(names(re[["rcs"]][[k]]))
          for (g in names(rcs[[k]])) {
            rcs[[k]][[g]] <- .predictor_re(
              Z = p(re[["Zcs"]][[g]], i),
              r = re[["rcs"]][[k]][[g]]
            )
          }
          rcs[[k]] <- Reduce("+", rcs[[k]])
        }
      } else {
        rcs <- NULL
      }
      eta <- .predictor_cs(
        eta, X = p(cs[["Xcs"]], i), 
        b = cs[["bcs"]], ncat = ncat, r = rcs
      )
      rm(rcs)
    } else {
      eta <- array(eta, dim = c(dim(eta), ncat - 1))
    } 
    for (k in seq_len(ncat - 1)) {
      if (draws$f$family %in% c("cumulative", "sratio")) {
        eta[, , k] <- cs[["Intercept"]][, k] - eta[, , k]
      } else {
        eta[, , k] <- eta[, , k] - cs[["Intercept"]][, k]
      }
    }
  } else if (isTRUE(draws$old_cat > 0L)) {
    if (draws$old_cat == 1L) {
      # deprecated as of brms > 0.8.0
      if (!is.null(cs[["bcs"]])) {
        eta <- .predictor_cs(
          eta, X = p(cs[["Xcs"]], i), b = cs[["bcs"]], 
          ncat = ncat
        )
      } else {
        eta <- array(eta, dim = c(dim(eta), ncat - 1))
      }
    } else if (draws$old_cat == 2L) {
      # deprecated as of brms > 0.10.0
      ncat1 <- ncat - 1 
      eta <- array(eta, dim = c(nrow(eta), ncol(eta) / ncat1, ncat1))
    }
  }
  eta
}

.predictor_cs <- function(eta, X, b, ncat, r = NULL) {
  # add category specific effects to eta
  # Args:
  #   X: category specific design matrix 
  #   b: category specific effects samples
  #   ncat: number of categories
  #   eta: linear predictor matrix
  #   r: list of samples of cs group-level effects
  # Returns: 
  #   linear predictor including category specific effects as a 3D array
  stopifnot(is.null(X) && is.null(b) || is.matrix(X) && is.matrix(b))
  ncat <- max(ncat)
  eta <- array(eta, dim = c(dim(eta), ncat - 1))
  if (!is.null(X)) {
    I <- seq(1, (ncat - 1) * ncol(X), ncat - 1) - 1
    X <- t(X)
  }
  for (k in seq_len(ncat - 1)) {
    if (!is.null(X)) {
      eta[, , k] <- eta[, , k] + b[, I + k, drop = FALSE] %*% X 
    }
    if (!is.null(r[[k]])) {
      eta[, , k] <- eta[, , k] + r[[k]]
    }
  }
  eta
}

predictor_offset <- function(draws, i, N) {
  if (is.null(draws$data$offset)) {
    return(0) 
  }
  eta <- rep(p(draws$data$offset, i), draws$nsamples)
  matrix(eta, ncol = N, byrow = TRUE)
}

predictor_autocor <- function(eta, draws, i) {
  # compute eta for autocorrelation structures
  # eta has to be passed to this function in order for
  # ARMA structure to work correctly
  if (!is.null(draws[["arr"]])) {
    eta <- eta + 
      .predictor_fe(X = p(draws$data$Yarr, i), b = draws[["arr"]])
  }
  if (any(c("ar", "ma") %in% names(draws))) {
    if (!is.null(i)) {
      stop2("Pointwise evaluation is not yet implemented for ARMA models.")
    }
    eta <- .predictor_arma(
      eta, sdata = draws$data, ar = draws[["ar"]], 
      ma = draws[["ma"]], link = draws$f$link
    )
  }
  if (!is.null(draws[["car"]])) {
    car <- draws[["car"]]
    eta <- eta + .predictor_re(Z = p(car[["Zcar"]], i), r = car[["rcar"]])
  }
  if (!is.null(draws[["loclev"]])) {
    eta <- eta + p(draws[["loclev"]], i, row = FALSE)
  }
  eta
}

.predictor_arma <- function(eta, sdata, ar = NULL, ma = NULL, 
                            link = "identity") {
  # compute eta for ARMA effects
  # TODO: use C++ for this function
  # TODO: handle 3-dimensional eta
  # Args:
  #   eta: previous linear predictor samples
  #   sdata: the data initially passed to Stan
  #   ar: autoregressive samples (can be NULL)
  #   ma: moving average samples (can be NULL)
  #   link: the link function as character string
  # Returns:
  #   new linear predictor samples updated by ARMA effects
  if (is.null(ar) && is.null(ma)) {
    return(eta)
  }
  S <- nrow(eta)
  Kar <- ifelse(is.null(ar), 0, ncol(ar))
  Kma <- ifelse(is.null(ma), 0, ncol(ma))
  K <- max(sdata$J_lag, 1)
  Ks <- 1:K
  Y <- link(sdata$Y, link)
  N <- length(Y)
  E <- array(0, dim = c(S, K, K + 1))
  e <- matrix(0, nrow = S, ncol = K)
  zero_mat <- e
  zero_vec <- rep(0, S)
  for (n in 1:N) {
    if (Kma) {
      # add MA correlations
      eta[, n] <- eta[, n] + rowSums(ma * E[, 1:Kma, K])
    }
    e[, K] <- Y[n] - eta[, n]
    I <- seq_len(sdata$J_lag[n])
    if (length(I)) {
      E[, I, K + 1] <- e[, K + 1 - I]
    }
    if (Kar) {
      # add AR correlations
      eta[, n] <- eta[, n] + rowSums(ar * E[, 1:Kar, K])
    }
    # allows to keep the object size of e and E small
    E <- abind(E[, , 2:(K + 1), drop = FALSE], zero_mat)
    if (K > 1) {
      e <- cbind(e[, 2:K, drop = FALSE], zero_vec)
    }
  }
  eta
}

get_eta <- function(draws, i = NULL) {
  # extract the linear predictor of observation i from draws
  # Args:
  #   draws: a list generated by extract_draws
  #   i: either NULL or a vector (typically of length 1) 
  #      indicating the observations for which to extract eta
  # Returns:
  #   An S x N matrix, where N is the number of extracted observations
  if (is.numeric(draws)) {
    if (is.null(dim(draws))) {
      draws <- as.matrix(draws)
    }
    if (is.null(i)) {
      eta <- draws
    } else if (length(dim(draws)) == 3L) {
      eta <- draws[, i, , drop = FALSE]  
    } else {
      eta <- draws[, i, drop = FALSE]  
    }
  } else if (!is.null(draws[["nlpars"]])) {
    eta <- nonlinear_predictor(draws, i = i)
  } else if (!is.null(draws[["mv"]])) {
    eta <- linear_predictor_mv(draws, i = i)
  } else {
    eta <- linear_predictor(draws, i = i)
  }
  eta
}
