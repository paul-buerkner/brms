<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Running brms models with within-chain parallelization • brms</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Running brms models with within-chain parallelization">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">brms</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.22.12</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/brms_customfamilies.html">Define Custom Response Distributions with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_distreg.html">Estimating Distributional Models with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_families.html">Parameterization of Response Distributions in brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_missings.html">Handle Missing Values with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_monotonic.html">Estimating Monotonic Effects with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_multivariate.html">Estimating Multivariate Models with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_nonlinear.html">Estimating Non-Linear Models with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_phylogenetics.html">Estimating Phylogenetic Multilevel Models with brms</a></li>
    <li><a class="dropdown-item" href="../articles/brms_threading.html">Running brms models with within-chain parallelization</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/paul-buerkner/brms/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Running brms models with within-chain parallelization</h1>
                        <h4 data-toc-skip class="author">Sebastian Weber
&amp; Paul Bürkner</h4>
            
            <h4 data-toc-skip class="date">2025-06-24</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/paul-buerkner/brms/blob/HEAD/vignettes/brms_threading.Rmd" class="external-link"><code>vignettes/brms_threading.Rmd</code></a></small>
      <div class="d-none name"><code>brms_threading.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Full Bayesian inference is a computationally very demanding task and
often we wish to run our models faster in shorter walltime. With modern
computers we nowadays have multiple processors available on a given
machine such that the use of running the inference in parallel will
shorten the overall walltime. While between-chain parallelization is
straightforward by merely launching multiple chains at the same time,
the use of within-chain parallelization is more complicated in various
ways. This vignette aims to introduce the user to within-chain
parallelization with <strong>brms</strong>, since its efficient use
depends on various aspects specific to the users model.</p>
</div>
<div class="section level2">
<h2 id="quick-summary">Quick summary<a class="anchor" aria-label="anchor" href="#quick-summary"></a>
</h2>
<p>Assuming you have a <strong>brms</strong> model which you wish to
evaluate faster by using more cores per chain, for example:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_serial</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">count</span> <span class="op">~</span> <span class="va">zAge</span> <span class="op">+</span> <span class="va">zBase</span> <span class="op">*</span> <span class="va">Trt</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">|</span><span class="va">patient</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">epilepsy</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4</span>, cores <span class="op">=</span> <span class="fl">4</span>, backend <span class="op">=</span> <span class="st">"cmdstanr"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Then you can simply add threading support to an existing model with
the <code>update</code> mechanism as follows, provided your stan version
is at least 2.26 (whether using <code>rstan</code> or
<code>cmdstan</code>):</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_parallel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span></span>
<span>  <span class="va">fit_serial</span>, chains <span class="op">=</span> <span class="fl">2</span>, cores <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"cmdstanr"</span>, threads <span class="op">=</span> <span class="fu"><a href="../reference/threading.html">threading</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The example above assumes that 4 cores are available which are best
used without within-chain parallelization by running 4 chains in
parallel. When using within chain parallelization it is still advisable
to use just as many threads <em>in total</em> as you have CPU cores.
It’s thus sensible in this case to reduce the number of chains running
in parallel to just 2, but allow each chain to use 2 threads. Obviously
this will reduce the number of iterations in the posterior here as we
assumed a fixed amount of 4 cores.</p>
<ul>
<li>Only apply within-chain parallelization to large problems which take
more than a few minutes at least to calculate. The <code>epilepsy</code>
example above is actually too small to gain in speed (just a few seconds
per chain on this machine).</li>
<li>Within-chain parallelization is less efficient than between-chain
parallelization. So only use within-chain parallelism if more CPUs can
be used to run the entire analysis.</li>
<li>Due to details of the model and data-set, speedups with more cores
can be very limited. Not every model amends to within-chain
parallelization and an empirical evaluation is in some cases
advisable.</li>
<li>Enabling threading <em>usually</em> slows down any model to some
extent and this slowdown must be offset by sufficient cores per chain in
order to really gain in execution speed.</li>
<li>Doubling the execution speed with few cores is a lot easier than
obtaining larger speedups with even more cores.</li>
<li>Models with computationally expensive likelihoods are easier to
parallelize than less expensive likelihoods. For example, the Poisson
distribution involves expensive
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mi>Γ</mi></mrow><annotation encoding="application/x-tex">\log\Gamma</annotation></semantics></math>
functions whereas the normal likelihood is very cheap to calculate in
comparison.</li>
<li>Models with many parameters (e.g., multilevel models) carry a large
overhead when running in parallel.</li>
<li>With a larger overhead of the model, the likelihood must be
sufficiently expensive such that the relative computational cost of
likelihood to parallelization overhead is favorable.</li>
<li>Avoid using hyper-threading, that is, only use as many threads as
you have physical cores available.</li>
<li>Ensure that the data is randomly sorted such that consecutive
subsets of the data are roughly of the same computational effort.</li>
</ul>
</div>
<div class="section level2">
<h2 id="within-chain-parallelization">Within-chain parallelization<a class="anchor" aria-label="anchor" href="#within-chain-parallelization"></a>
</h2>
<p>The within-chain parallelization implemented in <strong>brms</strong>
is based on the <code>reduce_sum</code> facility in Stan. The basic
principle that <code>reduce_sum</code> uses is to split a large
summation into arbitrary smaller partial sums. Due to the commutativity
and associativity of the sum operation these smaller partial sums can be
evaluated in any order and in parallel from one another.
<strong>brms</strong> leverages <code>reduce_sum</code> to evaluate the
log-likelihood of the model in parallel as for example</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>l</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>l</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>S</mi><mn>1</mn></msub></munderover><msub><mi>l</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><msub><mi>S</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>l</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
l(y|\theta) &amp;= \sum_{i=1}^N l_i(y_i| \theta) \\
 &amp;= \sum_{i=1}^{S_1} l_i(y_i| \theta) + \sum_{i=S_1+1}^N l_i(y_i| \theta).
\end{aligned}
</annotation></semantics></math></p>
<p>As a consequence, the within-chain parallelization requires mutually
independent log-likelihood terms which restricts its applicability to
some degree.</p>
<p>Furthermore, the within-chain parallelization is only applicable to
the evaluation of the data likelihood while all other parts of the
model, for example priors, will remain running serially. Thus, only a
partial fraction of the entire Stan model will run in parallel which
limits the potential speedup one may obtain. The theoretical speedup for
a partially in parallel running program is described by <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" class="external-link">Amdahl‘s law</a>.
For example, with 90% of the computational load running in parallel one
can essentially double the execution speed with 2 cores while 8 cores
may only speedup the program by at most 5x. How large the computational
cost of the log-likelihood is in relation to the entire model is very
dependent on the model of the user.</p>
<p>In practice, the speedups are even smaller than the theoretical
speedups. This is caused by the additional overhead implied by forming
multiple smaller sums than just one large one. For example, for each
partial sum formed the entire parameter vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
has to be copied in memory for Stan to be able to calculate the gradient
of the log-likelihood. Hence, with more partial sums, more copying is
necessary as opposed to evaluating just one large sum. Whether the
additional copying is indeed relevant depends on the computational cost
of the log-likelihood of each term and the number of parameters. For a
model with a computationally cheap normal log-likelihood, this effect is
more important than for a model with a Poisson log-likelihood, and for
multilevel models with many parameters more copying is needed than for
simpler regression models. It may therefore be necessary to form
sufficiently large partial sums to warrant an efficient parallel
execution. The size of the partial sums is referred to as the
<code>grainsize</code>, which is set to a reasonable default value.
However, for some models this tuning parameter requires some attention
from the user for optimal performance.</p>
<p>Finally, it is important to note that by default the exact size and
order of the partial sums is not stable as it is adjusted to the load of
the system. As a result, exact numerical reproducibility is not
guaranteed by default. In order to warrant the same size and order of
the partial sums, the <code>static</code> option must be used and set to
<code>TRUE</code>, which uses a deterministic scheduler for the parallel
work.</p>
</div>
<div class="section level2">
<h2 id="example-model">Example model<a class="anchor" aria-label="anchor" href="#example-model"></a>
</h2>
<p>As a toy demonstration, we use here a multilevel Poisson model. The
model is a varying intercept model with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>10</mn><mn>4</mn></msup><annotation encoding="application/x-tex">10^{4}</annotation></semantics></math>
data observation which are grouped into
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1000</mn><annotation encoding="application/x-tex">1000</annotation></semantics></math>
groups. Each data item has
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>3</mn><annotation encoding="application/x-tex">3</annotation></semantics></math>
continuous covariates. The simulation code for the fake data can be
found in the appendix and it’s first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>10</mn><annotation encoding="application/x-tex">10</annotation></semantics></math>
rows are:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">kable</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">fake</span>, <span class="fl">10</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<p>The <strong>brms</strong> model fitting this data is:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_poisson</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">g</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">fake</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  iter <span class="op">=</span> <span class="fl">500</span>, <span class="co"># short sampling to speedup example</span></span>
<span>  chains <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  prior <span class="op">=</span> <span class="fu"><a href="../reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu"><a href="../reference/constant.html">constant</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, group <span class="op">=</span> <span class="va">g</span><span class="op">)</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"cmdstanr"</span>,</span>
<span>  threads <span class="op">=</span> <span class="fu"><a href="../reference/threading.html">threading</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  save_pars <span class="op">=</span> <span class="fu"><a href="../reference/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Here we have fixed the standard deviation of the between-group
variation for the intercept to the true value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
as used in the simulation. This is to avoid unfavorable geometry of the
problem allowing us to concentrate on computational aspects alone.</p>
<p>The Poisson likelihood is a relatively expensive likelihood due to
the use of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mi>Γ</mi></mrow><annotation encoding="application/x-tex">\log\Gamma</annotation></semantics></math>
function as opposed to, for example, a normal likelihood which does is
by far less expensive operations. Moreover, this example is chosen in
order to demonstrate parallelization overhead implied by a large number
of parameters.</p>
</div>
<div class="section level2">
<h2 id="managing-parallelization-overhead">Managing parallelization overhead<a class="anchor" aria-label="anchor" href="#managing-parallelization-overhead"></a>
</h2>
<p>As discussed above, the key mechanism to run Stan programs with
parallelization is to split the large sum over independent log
likelihood terms into arbitrary smaller <em>partial sums</em>. Creating
more <em>partial sums</em> allows to increase simultaneous parallel
computations in a granular way, but at the same time additional overhead
is introduced through the requirement to copy the entire parameter
vector for each <em>partial sum</em> formed along with further overhead
due to splitting up a single large task into multiple smaller ones.</p>
<p>By default, <strong>brms</strong> will choose a sensible
<code>grainsize</code> which defines how large a given <em>partial
sum</em> will roughly be. The actual chunk size is automatically tuned
whenever the default non-static scheduler is used, which is the
recommended choice to start with. As noted before, only the static
scheduler is giving fully deterministic results since the chunk size and
order of partial sums will be the same during sampling.</p>
<p>While we expect that the default <code>grainsize</code> in
<strong>brms</strong> is reasonably good for many models, it can improve
performance if one tunes the <code>grainsize</code> specifically to a
given model and data-set. We suggest to increase successively the number
of chunks a given data set is split into with the static scheduler and
run this on a single core. This way one can control the number of
<em>partial sum</em> accurately and monitor the execution time as it
increases. These experiments are run with only a single chain and very
short iteration numbers as we are not interested in the statistical
results, but rather aim to be able to explore the tuning parameter space
of the chunk size as quickly as possible. The number of iterations
needed to get reliable runtime estimates for a given chunk size will
depend on many details and the easiest way to determine this is to run
this benchmark with multiple number of iterations. Whenever their
results match approximately, then the iteration numbers are sufficient.
In order to decrease the variation between runs, we also fix the random
seed, initial value and the tuning parameters of the sampler (step size
and mass matrix).</p>
<p>Below is an example R code demonstrating such a benchmark. The
utility function <code>benchmark_threading</code> is shown and explained
in the appendix.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">chunking_bench</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>chunks <span class="op">=</span> <span class="fl">4</span><span class="op">^</span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    grainsize <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling</a></span><span class="op">(</span><span class="va">N</span> <span class="op">/</span> <span class="va">chunks</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">iter_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">40</span><span class="op">)</span>  <span class="co"># very short test runs</span></span>
<span><span class="va">scaling_chunking</span> <span class="op">&lt;-</span> <span class="fu">benchmark_threading</span><span class="op">(</span></span>
<span>  <span class="va">model_poisson</span>,</span>
<span>  cores <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  grainsize <span class="op">=</span> <span class="va">chunking_bench</span><span class="op">$</span><span class="va">grainsize</span>,  <span class="co"># test various grainsizes</span></span>
<span>  iter <span class="op">=</span> <span class="va">iter_test</span>,</span>
<span>  static <span class="op">=</span> <span class="cn">TRUE</span>  <span class="co"># with static partitioner</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># run as reference the model *without* reduce_sum</span></span>
<span><span class="va">ref</span> <span class="op">&lt;-</span> <span class="fu">benchmark_reference</span><span class="op">(</span><span class="va">model_poisson</span>, <span class="va">iter_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># for additional data munging please refer to the appendix</span></span></code></pre></div>
<p>Graphically summarizing the results shows that with more than 8
chunks the overhead is about 10% and increasing further with more
chunks. For models without many parameters, no such overhead should be
observed. Furthermore, one can see that 25 and 50 iterations give
similar results implying that 25 iterations suffice for stable runtime
estimates for these (and the following) benchmarks. The overhead of up
to 20% in this example with 16 chunks may seem large due to the scaling
of the plot. One must not forget that when we start to use more CPU
cores, the overhead is easily offset, but it limits the maximal speedup
we can get. For example, some 2 units of computation become 2.4 units
due to the overhead such that on 2 cores we don’t quite double the
execution speed, but rather get a 1.6x increase in speed instead of a 2x
speedup.</p>
<p>Considering in addition the time per leapfrog step of the NUTS
sampler shows on an absolute scale similar information as before. The
upside of this representation is that we can visualize the slowdown in
relation to the program <em>without</em> <code>reduce_sum</code>. As we
can see, the additional overhead due to merely enabling
<code>reduce_sum</code> is substantial in this example. This is
attributed in the specific example to the large number of random
effects.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">scaling_chunking</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">chunks</span>, <span class="va">slowdown</span>, colour <span class="op">=</span> <span class="va">iter</span>, shape <span class="op">=</span> <span class="va">iter</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_log10</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="va">scaling_chunking</span><span class="op">$</span><span class="va">chunks</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_log10</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.8</span>, <span class="fl">2.5</span>, by<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Slowdown with increasing number of chunks"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">scaling_chunking</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">chunks</span>, <span class="fl">1E3</span> <span class="op">*</span> <span class="va">runtime</span><span class="op">/</span><span class="va">num_leapfrog</span>, colour <span class="op">=</span> <span class="va">iter</span>, shape<span class="op">=</span><span class="va">iter</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_log10</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="va">scaling_chunking</span><span class="op">$</span><span class="va">chunks</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_log10</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">2.0</span>, by<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">ref</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>yintercept<span class="op">=</span><span class="fl">1E3</span> <span class="op">*</span> <span class="va">runtime</span><span class="op">/</span><span class="va">num_leapfrog</span>, colour<span class="op">=</span><span class="va">iter</span><span class="op">)</span>, linetype<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Time per leapfrog step vs number of chunks"</span>,</span>
<span>            <span class="st">"Dashed line is reference model without reduce_sum"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ylab</a></span><span class="op">(</span><span class="st">"Time per leapfrog step [ms]"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="parallelization-speedup">Parallelization speedup<a class="anchor" aria-label="anchor" href="#parallelization-speedup"></a>
</h2>
<p>In practice, we are often interested in so-called “hard-scaling”
properties of the parallelization system. That is, for a fixed problem
size we would like to know how much faster we can execute the Stan
program with increasing number of threads. As nowadays CPUs usually run
with so-called hyper-threading, it is also of interest if this technique
is beneficial for Stan programs as well (spoiler alert: it’s not
useful). As we have seen before, the <code>grainsize</code> can have an
impact on the performance and is as such a tuning parameter. Below we
demonstrate some exemplary R code which runs a benchmark with varying
number of CPU cores and varying number of <code>grainsize</code>s.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">num_cpu</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span>logical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">num_cpu_logical</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span>logical <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">grainsize_default</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling</a></span><span class="op">(</span><span class="va">N</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">num_cpu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">^</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">floor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log2</a></span><span class="op">(</span><span class="va">num_cpu_logical</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, <span class="va">num_cpu</span>, <span class="va">num_cpu_logical</span><span class="op">)</span></span>
<span><span class="va">cores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">cores</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">grainsize</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">grainsize_default</span>, <span class="va">grainsize_default</span><span class="op">/</span><span class="fl">2</span>, <span class="va">grainsize_default</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">grainsize</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">grainsize</span><span class="op">)</span></span>
<span></span>
<span><span class="va">iter_scaling</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">scaling_cores</span> <span class="op">&lt;-</span> <span class="fu">benchmark_threading</span><span class="op">(</span></span>
<span>  <span class="va">model_poisson</span>,</span>
<span>  cores <span class="op">=</span> <span class="va">cores</span>,</span>
<span>  grainsize <span class="op">=</span> <span class="va">grainsize</span>,</span>
<span>  iter <span class="op">=</span> <span class="va">iter_scaling</span>,</span>
<span>  static <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">single_core</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="../reference/addition-terms.html">subset</a></span><span class="op">(</span><span class="va">scaling_cores</span>, <span class="va">cores</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    runtime_single <span class="op">=</span> <span class="va">runtime</span>,</span>
<span>    num_leapfrog<span class="op">=</span><span class="cn">NULL</span>, runtime<span class="op">=</span><span class="cn">NULL</span>, cores <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">scaling_cores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/merge.html" class="external-link">merge</a></span><span class="op">(</span><span class="va">scaling_cores</span>, <span class="va">single_core</span><span class="op">)</span>,</span>
<span>  speedup <span class="op">=</span> <span class="va">runtime_single</span><span class="op">/</span><span class="va">runtime</span>,</span>
<span>  grainsize <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">grainsize</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>It is important to consider the absolute runtime and the relative
speedup vs. running on a single core. The relative speedup can be
misleading if the single core runtime is very slow in which case speed
gains on more CPUs may look overly good. Considering instead the
absolute runtime avoids this problem. After all, we are interested in
the shortest walltime we can get rather than any relative speedups.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">scaling_cores</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">cores</span>, <span class="va">runtime</span>, shape <span class="op">=</span> <span class="va">grainsize</span>, color <span class="op">=</span> <span class="va">grainsize</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">num_cpu</span>, linetype <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_log10</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="va">scaling_cores</span><span class="op">$</span><span class="va">cores</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_log10</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">1.4</span>, by<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.85</span>, <span class="fl">0.8</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="../reference/addition-terms.html">subset</a></span><span class="op">(</span><span class="va">ref</span>, <span class="va">iter</span><span class="op">==</span><span class="va">iter_scaling</span><span class="op">)</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>yintercept<span class="op">=</span><span class="va">runtime</span><span class="op">)</span>, linetype<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Runtime with varying number of cores"</span>,</span>
<span>            <span class="st">"Dashed line is reference model without reduce_sum"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">scaling_cores</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">cores</span>, <span class="va">speedup</span>, shape <span class="op">=</span> <span class="va">grainsize</span>, color <span class="op">=</span> <span class="va">grainsize</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>slope <span class="op">=</span> <span class="fl">1</span>, intercept <span class="op">=</span> <span class="fl">0</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">num_cpu</span>, linetype <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_log10</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="va">scaling_cores</span><span class="op">$</span><span class="va">cores</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_log10</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="va">scaling_cores</span><span class="op">$</span><span class="va">cores</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>aspect.ratio <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html" class="external-link">coord_fixed</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">num_cpu_logical</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">num_cpu_logical</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Relative speedup vs 1 core"</span><span class="op">)</span></span></code></pre></div>
<p>The vertical dotted line marks the physical number of CPU cores on
the machine this was run. The horizontal dashed line in the plot with
absolute runtime marks the respective runtime of the model
<em>without</em> <code>reduce_sum</code> and the dashed unity line in
the plot with the relative speedup marks the theoretical maximal
speedup. We can see that there is no further reduction in execution time
when increasing the thread count to be greater than the number of
physical CPUs. Hence, the use of hyper-threading is not helpful when
aiming to maximize the speed of a Stan program. Moreover, the use of
threading outperforms the single core runtime only when using more than
4 cores in this example.</p>
<p>For this example, the shown <code>grainsize</code>s matter on some
machines but not on others, so your results may look quite different
from what is shown here. The overall speedups may not seem impressive in
this case, which is attributed in this case to the large number of
parameters relative to the number of observations. However, we can still
outperform the single core runtime when using many cores. Though the
most important advantage of threading is that with an increasing data
set size, the user has the option to use a brute-force approach to
balance the increase in walltime needed.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">kable</span><span class="op">(</span><span class="va">scaling_cores</span>, digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p>For a given Stan model one should usually choose the number of chains
and the number of threads per chain to be equal to the number of
(physical) cores one wishes to use. Only if different chains of the
model have relatively different execution times (which they should not
have, but it occurs sometimes in practice), then one may consider the
use of hyper-threading. Doing so will share the resources evenly across
all chains and whenever the fastest chain finishes, the freed resources
can be given to the still running chains.</p>
</div>
<div class="section level2">
<h2 id="appendix">Appendix<a class="anchor" aria-label="anchor" href="#appendix"></a>
</h2>
<div class="section level3">
<h3 id="fake-data-simulation">Fake data simulation<a class="anchor" aria-label="anchor" href="#fake-data-simulation"></a>
</h3>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">54647</span><span class="op">)</span></span>
<span><span class="co"># number of observations</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1E4</span></span>
<span><span class="co"># number of group levels</span></span>
<span><span class="va">G</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">N</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co"># number of predictors</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span><span class="co"># regression coefficients</span></span>
<span><span class="va">beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">P</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># sampled covariates, group means and fake data</span></span>
<span><span class="va">fake</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span> <span class="op">*</span> <span class="va">P</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">P</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dimnames.html" class="external-link">dimnames</a></span><span class="op">(</span><span class="va">fake</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">P</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fixed effect part and sampled group membership</span></span>
<span><span class="va">fake</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">fake</span><span class="op">)</span>,</span>
<span>  theta <span class="op">=</span> <span class="va">fake</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span>,</span>
<span>  g <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample.int</a></span><span class="op">(</span><span class="va">G</span>, <span class="va">N</span>, replace<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># add random intercept by group</span></span>
<span><span class="va">fake</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/merge.html" class="external-link">merge</a></span><span class="op">(</span><span class="va">fake</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>g <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">G</span>, eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">G</span><span class="op">)</span><span class="op">)</span>, by <span class="op">=</span> <span class="st">"g"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># linear predictor</span></span>
<span><span class="va">fake</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">fake</span>, mu <span class="op">=</span> <span class="va">theta</span> <span class="op">+</span> <span class="va">eta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># sample Poisson data</span></span>
<span><span class="va">fake</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">fake</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span><span class="va">N</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># shuffle order of data rows to ensure even distribution of computational effort</span></span>
<span><span class="va">fake</span> <span class="op">&lt;-</span> <span class="va">fake</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample.int</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">N</span><span class="op">)</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co"># drop not needed row names</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">fake</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="poisson-example-model">Poisson example model<a class="anchor" aria-label="anchor" href="#poisson-example-model"></a>
</h3>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_poisson</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">g</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">fake</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  iter <span class="op">=</span> <span class="fl">500</span>, <span class="co"># short sampling to speedup example</span></span>
<span>  chains <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  prior <span class="op">=</span> <span class="fu"><a href="../reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu"><a href="../reference/constant.html">constant</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sd</span>, group <span class="op">=</span> <span class="va">g</span><span class="op">)</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"cmdstanr"</span>,</span>
<span>  threads <span class="op">=</span> <span class="fu"><a href="../reference/threading.html">threading</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  save_pars <span class="op">=</span> <span class="fu"><a href="../reference/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="threading-benchmark-function">Threading benchmark function<a class="anchor" aria-label="anchor" href="#threading-benchmark-function"></a>
</h3>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Benchmarks given model with cross-product of tuning parameters CPU</span></span>
<span><span class="co"># cores, grainsize and iterations. Models are run with either static</span></span>
<span><span class="co"># or non-static scheduler and initial values are set by default to 0 on the</span></span>
<span><span class="co"># unconstrained scale. Function returns a data-frame with the</span></span>
<span><span class="co"># cross-product of the tuning parameters and as result column the</span></span>
<span><span class="co"># respective runtime.</span></span>
<span><span class="va">benchmark_threading</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">cores</span> <span class="op">=</span> <span class="fl">1</span>, <span class="va">grainsize</span> <span class="op">=</span> <span class="fl">1</span>, <span class="va">iter</span> <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                                <span class="va">static</span> <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="va">winfo</span> <span class="op">&lt;-</span> <span class="fu">extract_warmup_info</span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span>    <span class="va">sims</span>  <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-extract.html" class="external-link">extract</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span>
<span>    <span class="va">init</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">extract_draw</span><span class="op">(</span><span class="va">sims</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">scaling_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span></span>
<span>        <span class="va">model</span>, refresh <span class="op">=</span> <span class="fl">0</span>,</span>
<span>        threads <span class="op">=</span> <span class="fu"><a href="../reference/threading.html">threading</a></span><span class="op">(</span><span class="fl">1</span>, grainsize <span class="op">=</span> <span class="va">grainsize</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, static <span class="op">=</span> <span class="va">static</span><span class="op">)</span>,</span>
<span>        chains <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">2</span>, backend <span class="op">=</span> <span class="st">"cmdstanr"</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span>    <span class="va">run_benchmark</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">cores</span>, <span class="va">size</span>, <span class="va">iter</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">bench_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span></span>
<span>            <span class="va">scaling_model</span>, warmup<span class="op">=</span><span class="fl">0</span>, iter <span class="op">=</span> <span class="va">iter</span>,</span>
<span>            chains <span class="op">=</span> <span class="fl">1</span>, seed <span class="op">=</span> <span class="fl">1234</span>, init <span class="op">=</span> <span class="va">init</span>, refresh <span class="op">=</span> <span class="fl">0</span>, save_warmup<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>            threads <span class="op">=</span> <span class="fu"><a href="../reference/threading.html">threading</a></span><span class="op">(</span><span class="va">cores</span>, grainsize <span class="op">=</span> <span class="va">size</span>, static <span class="op">=</span> <span class="va">static</span><span class="op">)</span>,</span>
<span>            inv_metric<span class="op">=</span><span class="va">winfo</span><span class="op">$</span><span class="va">inv_metric</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>            step_size<span class="op">=</span><span class="va">winfo</span><span class="op">$</span><span class="va">step_size</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>            adapt_engaged<span class="op">=</span><span class="cn">FALSE</span></span>
<span>        <span class="op">)</span></span>
<span>        <span class="va">lf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="../reference/addition-terms.html">subset</a></span><span class="op">(</span><span class="fu"><a href="../reference/diagnostic-quantities.html">nuts_params</a></span><span class="op">(</span><span class="va">bench_fit</span>, inc_warmup<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>, <span class="va">Parameter</span><span class="op">==</span><span class="st">"n_leapfrog__"</span><span class="op">)</span><span class="op">$</span><span class="va">Value</span><span class="op">)</span></span>
<span>        <span class="va">elapsed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colSums</a></span><span class="op">(</span><span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-class.html" class="external-link">get_elapsed_time</a></span><span class="op">(</span><span class="va">bench_fit</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>num_leapfrog<span class="op">=</span><span class="va">lf</span>, runtime<span class="op">=</span><span class="va">elapsed</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span></span>
<span>    <span class="va">cases</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="va">cores</span>, grainsize <span class="op">=</span> <span class="va">grainsize</span>, iter <span class="op">=</span> <span class="va">iter</span><span class="op">)</span></span>
<span>    <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">cases</span>, <span class="fu"><a href="https://rdrr.io/r/base/mapply.html" class="external-link">mapply</a></span><span class="op">(</span><span class="va">run_benchmark</span>, <span class="va">cores</span>, <span class="va">grainsize</span>, <span class="va">iter</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://amices.org/mice/reference/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">cases</span>, <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">benchmark_reference</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">iter</span><span class="op">=</span><span class="fl">100</span>, <span class="va">init</span><span class="op">=</span><span class="fl">0</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">winfo</span> <span class="op">&lt;-</span> <span class="fu">extract_warmup_info</span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span>    <span class="va">sims</span>  <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-extract.html" class="external-link">extract</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span>
<span>    <span class="va">init</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">extract_draw</span><span class="op">(</span><span class="va">sims</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">ref_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span></span>
<span>        <span class="va">model</span>, refresh <span class="op">=</span> <span class="fl">0</span>, threads <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>        chains <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">2</span>, backend <span class="op">=</span> <span class="st">"cmdstanr"</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span>    <span class="va">run_benchmark_ref</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">iter_bench</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">bench_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span></span>
<span>            <span class="va">ref_model</span>, warmup<span class="op">=</span><span class="fl">0</span>, iter <span class="op">=</span> <span class="va">iter_bench</span>,</span>
<span>            chains <span class="op">=</span> <span class="fl">1</span>, seed <span class="op">=</span> <span class="fl">1234</span>, init <span class="op">=</span> <span class="va">init</span>, refresh <span class="op">=</span> <span class="fl">0</span>,</span>
<span>            inv_metric<span class="op">=</span><span class="va">winfo</span><span class="op">$</span><span class="va">inv_metric</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>            step_size<span class="op">=</span><span class="va">winfo</span><span class="op">$</span><span class="va">step_size</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>,</span>
<span>            adapt_engaged<span class="op">=</span><span class="cn">FALSE</span></span>
<span>        <span class="op">)</span></span>
<span></span>
<span>        <span class="va">lf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="../reference/addition-terms.html">subset</a></span><span class="op">(</span><span class="fu"><a href="../reference/diagnostic-quantities.html">nuts_params</a></span><span class="op">(</span><span class="va">bench_fit</span>, inc_warmup<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>, <span class="va">Parameter</span><span class="op">==</span><span class="st">"n_leapfrog__"</span><span class="op">)</span><span class="op">$</span><span class="va">Value</span><span class="op">)</span></span>
<span>        <span class="va">elapsed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colSums</a></span><span class="op">(</span><span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-class.html" class="external-link">get_elapsed_time</a></span><span class="op">(</span><span class="va">bench_fit</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>num_leapfrog<span class="op">=</span><span class="va">lf</span>, runtime<span class="op">=</span><span class="va">elapsed</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span></span>
<span>    <span class="va">ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="va">iter</span>, <span class="va">run_benchmark_ref</span><span class="op">)</span></span>
<span>    <span class="va">ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://amices.org/mice/reference/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">ref</span><span class="op">)</span><span class="op">)</span>, iter<span class="op">=</span><span class="va">iter</span><span class="op">)</span></span>
<span>    <span class="va">ref</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">extract_warmup_info</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">bfit</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">adapt</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-class.html" class="external-link">get_adaptation_info</a></span><span class="op">(</span><span class="va">bfit</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span>, <span class="va">strsplit</span>, split<span class="op">=</span><span class="st">"\\n"</span><span class="op">)</span></span>
<span>    <span class="va">step_size</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">adapt</span>, <span class="kw">function</span><span class="op">(</span><span class="va">a</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/strsplit.html" class="external-link">strsplit</a></span><span class="op">(</span><span class="va">a</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>, <span class="st">" = "</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">inv_metric</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">adapt</span>, <span class="kw">function</span><span class="op">(</span><span class="va">a</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/strsplit.html" class="external-link">strsplit</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">sub</a></span><span class="op">(</span><span class="st">"^# "</span>, <span class="st">""</span>, <span class="va">a</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>, <span class="st">", "</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>step_size<span class="op">=</span><span class="va">step_size</span>, inv_metric<span class="op">=</span><span class="va">inv_metric</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">extract_draw</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sims</span>, <span class="va">draw</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">sims</span>, <span class="fu">brms</span><span class="fu">:::</span><span class="va">slice</span>, dim <span class="op">=</span> <span class="fl">1</span>, i <span class="op">=</span> <span class="va">draw</span>, drop <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="munging-of-slowdown-with-chunking-data">Munging of slowdown with chunking data<a class="anchor" aria-label="anchor" href="#munging-of-slowdown-with-chunking-data"></a>
</h3>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">scaling_chunking</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/merge.html" class="external-link">merge</a></span><span class="op">(</span><span class="va">scaling_chunking</span>, <span class="va">chunking_bench</span>, by <span class="op">=</span> <span class="st">"grainsize"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">single_chunk</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="../reference/addition-terms.html">subset</a></span><span class="op">(</span><span class="va">scaling_chunking</span>, <span class="va">chunks</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    num_leapfrog_single <span class="op">=</span> <span class="va">num_leapfrog</span>, num_leapfrog <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    runtime_single <span class="op">=</span> <span class="va">runtime</span>, runtime <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    grainsize <span class="op">=</span> <span class="cn">NULL</span>, chunks<span class="op">=</span><span class="cn">NULL</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">scaling_chunking</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/merge.html" class="external-link">merge</a></span><span class="op">(</span><span class="va">scaling_chunking</span>, <span class="va">single_chunk</span><span class="op">)</span>,</span>
<span>    slowdown <span class="op">=</span> <span class="va">runtime</span><span class="op">/</span><span class="va">runtime_single</span>,</span>
<span>    iter <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">iter</span><span class="op">)</span>,</span>
<span>    runtime_single <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html" class="external-link">transform</a></span><span class="op">(</span><span class="va">ref</span>, iter<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">iter</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Paul-Christian Bürkner.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
